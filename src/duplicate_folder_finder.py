#!/usr/bin/env python3
"""
Duplicate Folder Finder (Kopya KlasÃ¶r Bulucu)
Ã–zdeÅŸ klasÃ¶r aÄŸaÃ§larÄ±nÄ± bulur
"""

import os
import hashlib
import logging
from typing import List, Dict, Tuple, Optional, Set
from collections import defaultdict
import json

logger = logging.getLogger(__name__)


class FolderFingerprint:
    """KlasÃ¶r parmak izi - klasÃ¶rÃ¼n yapÄ±sÄ±nÄ± ve iÃ§eriÄŸini temsil eder"""
    
    def __init__(self, folder_path: str):
        self.folder_path = folder_path
        self.file_hashes = {}  # {relative_path: md5_hash}
        self.folder_structure = []  # Alt klasÃ¶r yapÄ±sÄ±
        self.total_size = 0
        self.file_count = 0
        
    def calculate(self, ignore_hidden: bool = True) -> str:
        """
        KlasÃ¶r parmak izini hesaplar
        
        Returns:
            KlasÃ¶rÃ¼n benzersiz fingerprint'i
        """
        if not os.path.exists(self.folder_path):
            return ""
        
        # TÃ¼m dosyalarÄ± ve klasÃ¶rleri tara
        for root, dirs, files in os.walk(self.folder_path):
            # Gizli klasÃ¶rleri atla
            if ignore_hidden:
                dirs[:] = [d for d in dirs if not d.startswith('.')]
                files = [f for f in files if not f.startswith('.')]
            
            # KlasÃ¶r yapÄ±sÄ±nÄ± kaydet
            rel_root = os.path.relpath(root, self.folder_path)
            if rel_root != '.':
                self.folder_structure.append(rel_root)
            
            # Dosya hash'lerini hesapla
            for filename in sorted(files):
                file_path = os.path.join(root, filename)
                rel_path = os.path.relpath(file_path, self.folder_path)
                
                try:
                    file_size = os.path.getsize(file_path)
                    self.total_size += file_size
                    self.file_count += 1
                    
                    # KÃ¼Ã§Ã¼k dosyalar iÃ§in tam hash, bÃ¼yÃ¼kler iÃ§in sample hash
                    if file_size < 10 * 1024 * 1024:  # 10MB altÄ±
                        file_hash = self._calculate_file_hash(file_path)
                    else:
                        file_hash = self._calculate_sample_hash(file_path)
                    
                    self.file_hashes[rel_path] = file_hash
                    
                except Exception as e:
                    logger.warning(f"Dosya hash hesaplanamadÄ± ({file_path}): {e}")
        
        # KlasÃ¶r fingerprint'ini oluÅŸtur
        return self._generate_fingerprint()
    
    def _calculate_file_hash(self, file_path: str) -> str:
        """DosyanÄ±n MD5 hash'ini hesaplar"""
        hasher = hashlib.md5()
        try:
            with open(file_path, 'rb') as f:
                while chunk := f.read(8192):
                    hasher.update(chunk)
            return hasher.hexdigest()
        except Exception:
            return ""
    
    def _calculate_sample_hash(self, file_path: str) -> str:
        """BÃ¼yÃ¼k dosyalar iÃ§in Ã¶rnek hash (baÅŸlangÄ±Ã§ + son)"""
        hasher = hashlib.md5()
        sample_size = 1024 * 1024  # 1MB
        
        try:
            file_size = os.path.getsize(file_path)
            with open(file_path, 'rb') as f:
                # BaÅŸtan 1MB
                hasher.update(f.read(sample_size))
                
                # Ortadan 1MB
                if file_size > 3 * sample_size:
                    f.seek(file_size // 2)
                    hasher.update(f.read(sample_size))
                
                # Sondan 1MB
                if file_size > sample_size:
                    f.seek(-sample_size, 2)
                    hasher.update(f.read(sample_size))
                    
            return hasher.hexdigest()
        except Exception:
            return ""
    
    def _generate_fingerprint(self) -> str:
        """KlasÃ¶r fingerprint'ini oluÅŸturur"""
        fingerprint_data = {
            'structure': sorted(self.folder_structure),
            'files': sorted(self.file_hashes.items()),
            'file_count': self.file_count,
            'total_size': self.total_size
        }
        
        # JSON string'e Ã§evir ve hash al
        json_str = json.dumps(fingerprint_data, sort_keys=True)
        return hashlib.md5(json_str.encode()).hexdigest()


class DuplicateFolderFinder:
    """Duplicate klasÃ¶r bulucu ana sÄ±nÄ±fÄ±"""
    
    def __init__(self, 
                 min_file_count: int = 3,
                 ignore_hidden: bool = True,
                 match_exact: bool = True):
        """
        Args:
            min_file_count: Minimum dosya sayÄ±sÄ± (daha az dosyalÄ± klasÃ¶rler atlanÄ±r)
            ignore_hidden: Gizli dosya/klasÃ¶rleri yoksay
            match_exact: True ise tam eÅŸleÅŸme, False ise benzerlik
        """
        self.min_file_count = min_file_count
        self.ignore_hidden = ignore_hidden
        self.match_exact = match_exact
        self.fingerprints = {}  # {folder_path: fingerprint}
        
    def scan_directories(self, 
                        root_directories: List[str],
                        max_depth: Optional[int] = None) -> Dict[str, List[str]]:
        """
        Dizinleri tarar ve duplicate klasÃ¶rleri bulur
        
        Args:
            root_directories: Taranacak kÃ¶k dizinler
            max_depth: Maksimum tarama derinliÄŸi (None = sÄ±nÄ±rsÄ±z)
            
        Returns:
            Duplicate gruplar {fingerprint: [folder1, folder2, ...]}
        """
        logger.info(f"{len(root_directories)} dizin taranÄ±yor...")
        
        # TÃ¼m alt klasÃ¶rleri bul
        all_folders = []
        for root_dir in root_directories:
            folders = self._get_all_folders(root_dir, max_depth)
            all_folders.extend(folders)
        
        logger.info(f"{len(all_folders)} klasÃ¶r bulundu, fingerprint'ler hesaplanÄ±yor...")
        
        # Her klasÃ¶r iÃ§in fingerprint hesapla
        fingerprint_groups = defaultdict(list)
        
        for i, folder_path in enumerate(all_folders):
            if i % 100 == 0 and i > 0:
                logger.info(f"  Ä°ÅŸleniyor: {i}/{len(all_folders)}")
            
            fp = FolderFingerprint(folder_path)
            fingerprint = fp.calculate(self.ignore_hidden)
            
            # Minimum dosya sayÄ±sÄ± kontrolÃ¼
            if fp.file_count >= self.min_file_count:
                self.fingerprints[folder_path] = fp
                fingerprint_groups[fingerprint].append(folder_path)
        
        # Sadece duplicate olanlarÄ± filtrele
        duplicates = {fp: folders for fp, folders in fingerprint_groups.items() 
                     if len(folders) > 1}
        
        logger.info(f"{len(duplicates)} duplicate klasÃ¶r grubu bulundu")
        return duplicates
    
    def _get_all_folders(self, 
                        root_dir: str, 
                        max_depth: Optional[int] = None) -> List[str]:
        """
        TÃ¼m alt klasÃ¶rleri listeler
        
        Args:
            root_dir: KÃ¶k dizin
            max_depth: Maksimum derinlik
            
        Returns:
            KlasÃ¶r yollarÄ± listesi
        """
        folders = []
        
        try:
            for root, dirs, files in os.walk(root_dir):
                # Derinlik kontrolÃ¼
                if max_depth is not None:
                    depth = root[len(root_dir):].count(os.sep)
                    if depth >= max_depth:
                        dirs.clear()
                        continue
                
                # Gizli klasÃ¶rleri atla
                if self.ignore_hidden:
                    dirs[:] = [d for d in dirs if not d.startswith('.')]
                
                # Alt klasÃ¶rleri ekle
                for dir_name in dirs:
                    folder_path = os.path.join(root, dir_name)
                    folders.append(folder_path)
                    
        except PermissionError as e:
            logger.warning(f"Ä°zin hatasÄ±: {root_dir}")
        
        return folders
    
    def get_duplicate_stats(self, duplicates: Dict[str, List[str]]) -> Dict:
        """
        Duplicate istatistiklerini hesaplar
        
        Returns:
            Ä°statistik sÃ¶zlÃ¼ÄŸÃ¼
        """
        total_groups = len(duplicates)
        total_folders = sum(len(folders) for folders in duplicates.values())
        
        # Tasarruf edilebilir alan
        total_wasted_space = 0
        for fingerprint, folders in duplicates.items():
            if folders:
                # Ä°lk klasÃ¶rÃ¼ orijinal kabul et, geri kalanlar silinebilir
                first_folder = folders[0]
                if first_folder in self.fingerprints:
                    folder_size = self.fingerprints[first_folder].total_size
                    wasted_space = folder_size * (len(folders) - 1)
                    total_wasted_space += wasted_space
        
        return {
            'total_groups': total_groups,
            'total_duplicate_folders': total_folders,
            'original_folders': total_groups,
            'removable_folders': total_folders - total_groups,
            'wasted_space_bytes': total_wasted_space,
            'wasted_space_readable': self._format_size(total_wasted_space)
        }
    
    def _format_size(self, size_bytes: int) -> str:
        """Bayt cinsinden boyutu okunabilir formata Ã§evirir"""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.1f} {unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f} PB"
    
    def compare_folders(self, folder1: str, folder2: str) -> Dict:
        """
        Ä°ki klasÃ¶rÃ¼ karÅŸÄ±laÅŸtÄ±rÄ±r ve farklarÄ± gÃ¶sterir
        
        Returns:
            KarÅŸÄ±laÅŸtÄ±rma sonucu
        """
        fp1 = FolderFingerprint(folder1)
        fp2 = FolderFingerprint(folder2)
        
        fingerprint1 = fp1.calculate(self.ignore_hidden)
        fingerprint2 = fp2.calculate(self.ignore_hidden)
        
        is_identical = fingerprint1 == fingerprint2
        
        # FarklarÄ± bul
        files1 = set(fp1.file_hashes.keys())
        files2 = set(fp2.file_hashes.keys())
        
        only_in_folder1 = files1 - files2
        only_in_folder2 = files2 - files1
        common_files = files1 & files2
        
        # Ortak dosyalarda hash farklÄ±lÄ±klarÄ±
        different_content = []
        for file_path in common_files:
            if fp1.file_hashes[file_path] != fp2.file_hashes[file_path]:
                different_content.append(file_path)
        
        return {
            'is_identical': is_identical,
            'folder1': {
                'path': folder1,
                'file_count': fp1.file_count,
                'total_size': self._format_size(fp1.total_size)
            },
            'folder2': {
                'path': folder2,
                'file_count': fp2.file_count,
                'total_size': self._format_size(fp2.total_size)
            },
            'only_in_folder1': list(only_in_folder1),
            'only_in_folder2': list(only_in_folder2),
            'different_content': different_content,
            'similarity_percentage': self._calculate_similarity(fp1, fp2)
        }
    
    def _calculate_similarity(self, fp1: FolderFingerprint, fp2: FolderFingerprint) -> float:
        """Ä°ki klasÃ¶r arasÄ±ndaki benzerlik yÃ¼zdesini hesaplar"""
        files1 = set(fp1.file_hashes.keys())
        files2 = set(fp2.file_hashes.keys())
        
        if not files1 and not files2:
            return 100.0
        
        common = files1 & files2
        total = files1 | files2
        
        if not total:
            return 0.0
        
        # Dosya adÄ± benzerliÄŸi
        name_similarity = (len(common) / len(total)) * 100
        
        # Ä°Ã§erik benzerliÄŸi (ortak dosyalar iÃ§in)
        content_matches = sum(1 for f in common 
                            if fp1.file_hashes[f] == fp2.file_hashes[f])
        content_similarity = (content_matches / len(total)) * 100 if total else 0
        
        # Ortalama benzerlik
        return (name_similarity + content_similarity) / 2


# KullanÄ±m Ã¶rneÄŸi
if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    
    finder = DuplicateFolderFinder(
        min_file_count=3,
        ignore_hidden=True,
        match_exact=True
    )
    
    # Duplicate klasÃ¶rleri bul
    duplicates = finder.scan_directories(
        root_directories=['/home/user/Documents', '/media/backup'],
        max_depth=5
    )
    
    # SonuÃ§larÄ± gÃ¶ster
    print("\nğŸ“ Duplicate KlasÃ¶rler:")
    for i, (fingerprint, folders) in enumerate(duplicates.items(), 1):
        print(f"\nGrup {i}: {len(folders)} Ã¶zdeÅŸ klasÃ¶r")
        for folder in folders:
            fp = finder.fingerprints.get(folder)
            if fp:
                print(f"  ğŸ“‚ {folder}")
                print(f"     Dosya: {fp.file_count}, Boyut: {finder._format_size(fp.total_size)}")
    
    # Ä°statistikler
    stats = finder.get_duplicate_stats(duplicates)
    print(f"\nğŸ“Š Ä°statistikler:")
    print(f"  Toplam grup: {stats['total_groups']}")
    print(f"  Silinebilir klasÃ¶r: {stats['removable_folders']}")
    print(f"  Tasarruf edilebilir alan: {stats['wasted_space_readable']}")
